{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c1b1894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-core>=0.3.60 in /home/user/gen-ai/lib/python3.12/site-packages (from langchain-chroma) (0.3.64)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/user/gen-ai/lib/python3.12/site-packages (from langchain-chroma) (2.2.5)\n",
      "Collecting chromadb>=1.0.9 (from langchain-chroma)\n",
      "  Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (2.11.4)\n",
      "Collecting fastapi==0.115.9 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/user/gen-ai/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.34.2)\n",
      "Collecting posthog>=2.4.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading posthog-4.8.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (4.13.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading onnxruntime-1.22.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (0.21.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (0.15.3)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/user/gen-ai/lib/python3.12/site-packages (from chromadb>=1.0.9->langchain-chroma) (4.23.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /home/user/gen-ai/lib/python3.12/site-packages (from langchain-core>=0.3.60->langchain-chroma) (0.3.45)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/user/gen-ai/lib/python3.12/site-packages (from langchain-core>=0.3.60->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/user/gen-ai/lib/python3.12/site-packages (from langchain-core>=0.3.60->langchain-chroma) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio in /home/user/gen-ai/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/user/gen-ai/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/user/gen-ai/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/user/gen-ai/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/user/gen-ai/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/user/gen-ai/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.60->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/user/gen-ai/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/user/gen-ai/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/user/gen-ai/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/user/gen-ai/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.24.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/user/gen-ai/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/user/gen-ai/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/user/gen-ai/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.39.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/user/gen-ai/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.3.3)\n",
      "Requirement already satisfied: requests in /home/user/gen-ai/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /home/user/gen-ai/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/user/gen-ai/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/user/gen-ai/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.0.7)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/user/gen-ai/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.3.60->langchain-chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/user/gen-ai/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.3.60->langchain-chroma) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in /home/user/gen-ai/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (5.29.4)\n",
      "Requirement already satisfied: sympy in /home/user/gen-ai/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma) (0.52b1)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma) (0.52b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma) (3.8.1)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_util_http-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_api-1.34.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_api-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /home/user/gen-ai/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma) (0.53b1)\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/user/gen-ai/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/user/gen-ai/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb>=1.0.9->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/gen-ai/lib/python3.12/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/user/gen-ai/lib/python3.12/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/user/gen-ai/lib/python3.12/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/user/gen-ai/lib/python3.12/site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/user/gen-ai/lib/python3.12/site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/user/gen-ai/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (0.30.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/user/gen-ai/lib/python3.12/site-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/user/gen-ai/lib/python3.12/site-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/user/gen-ai/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/user/gen-ai/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/user/gen-ai/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/user/gen-ai/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/user/gen-ai/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (13.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/gen-ai/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/gen-ai/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/gen-ai/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (4.9.1)\n",
      "Requirement already satisfied: filelock in /home/user/gen-ai/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/gen-ai/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (2025.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/user/gen-ai/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/user/gen-ai/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/gen-ai/lib/python3.12/site-packages (from requests->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/user/gen-ai/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/user/gen-ai/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user/gen-ai/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/user/gen-ai/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.6.1)\n",
      "Downloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
      "Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading posthog-4.8.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=870f05500aef63cd0a6d7761374fde98590ba44ea757034ec334b6287d27195d\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, pyproject_hooks, opentelemetry-util-http, mmh3, importlib-resources, coloredlogs, starlette, posthog, onnxruntime, build, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
      "  Attempting uninstall: opentelemetry-util-http\n",
      "    Found existing installation: opentelemetry-util-http 0.52b1\n",
      "    Uninstalling opentelemetry-util-http-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-util-http-0.52b1\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.46.2\n",
      "    Uninstalling starlette-0.46.2:\n",
      "      Successfully uninstalled starlette-0.46.2\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.115.12\n",
      "    Uninstalling fastapi-0.115.12:\n",
      "      Successfully uninstalled fastapi-0.115.12\n",
      "  Attempting uninstall: opentelemetry-instrumentation\n",
      "    Found existing installation: opentelemetry-instrumentation 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-0.52b1\n",
      "  Attempting uninstall: opentelemetry-instrumentation-asgi\n",
      "    Found existing installation: opentelemetry-instrumentation-asgi 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-asgi-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-asgi-0.52b1\n",
      "  Attempting uninstall: opentelemetry-instrumentation-fastapi\n",
      "    Found existing installation: opentelemetry-instrumentation-fastapi 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-fastapi-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-fastapi-0.52b1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-instrumentation-psycopg2 0.52b1 requires opentelemetry-instrumentation==0.52b1, but you have opentelemetry-instrumentation 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib3 0.52b1 requires opentelemetry-instrumentation==0.52b1, but you have opentelemetry-instrumentation 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib3 0.52b1 requires opentelemetry-semantic-conventions==0.52b1, but you have opentelemetry-semantic-conventions 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib3 0.52b1 requires opentelemetry-util-http==0.52b1, but you have opentelemetry-util-http 0.53b1 which is incompatible.\n",
      "azure-monitor-opentelemetry 1.6.8 requires opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0, but you have opentelemetry-instrumentation-fastapi 0.53b1 which is incompatible.\n",
      "azure-monitor-opentelemetry 1.6.8 requires opentelemetry-sdk<1.32,>=1.28.0, but you have opentelemetry-sdk 1.32.1 which is incompatible.\n",
      "opentelemetry-instrumentation-flask 0.52b1 requires opentelemetry-instrumentation==0.52b1, but you have opentelemetry-instrumentation 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-flask 0.52b1 requires opentelemetry-semantic-conventions==0.52b1, but you have opentelemetry-semantic-conventions 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-flask 0.52b1 requires opentelemetry-util-http==0.52b1, but you have opentelemetry-util-http 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-wsgi 0.52b1 requires opentelemetry-instrumentation==0.52b1, but you have opentelemetry-instrumentation 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-wsgi 0.52b1 requires opentelemetry-semantic-conventions==0.52b1, but you have opentelemetry-semantic-conventions 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-wsgi 0.52b1 requires opentelemetry-util-http==0.52b1, but you have opentelemetry-util-http 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-django 0.52b1 requires opentelemetry-instrumentation==0.52b1, but you have opentelemetry-instrumentation 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-django 0.52b1 requires opentelemetry-semantic-conventions==0.52b1, but you have opentelemetry-semantic-conventions 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-django 0.52b1 requires opentelemetry-util-http==0.52b1, but you have opentelemetry-util-http 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-requests 0.52b1 requires opentelemetry-instrumentation==0.52b1, but you have opentelemetry-instrumentation 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-requests 0.52b1 requires opentelemetry-semantic-conventions==0.52b1, but you have opentelemetry-semantic-conventions 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-requests 0.52b1 requires opentelemetry-util-http==0.52b1, but you have opentelemetry-util-http 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-dbapi 0.52b1 requires opentelemetry-instrumentation==0.52b1, but you have opentelemetry-instrumentation 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-dbapi 0.52b1 requires opentelemetry-semantic-conventions==0.52b1, but you have opentelemetry-semantic-conventions 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib 0.52b1 requires opentelemetry-instrumentation==0.52b1, but you have opentelemetry-instrumentation 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib 0.52b1 requires opentelemetry-semantic-conventions==0.52b1, but you have opentelemetry-semantic-conventions 0.53b1 which is incompatible.\n",
      "opentelemetry-instrumentation-urllib 0.52b1 requires opentelemetry-util-http==0.52b1, but you have opentelemetry-util-http 0.53b1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed build-1.2.2.post1 chromadb-1.0.12 coloredlogs-15.0.1 durationpy-0.10 fastapi-0.115.9 flatbuffers-25.2.10 importlib-resources-6.5.2 kubernetes-33.1.0 langchain-chroma-0.2.4 mmh3-5.1.0 onnxruntime-1.22.0 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-util-http-0.53b1 posthog-4.8.0 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.45.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import json, os\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b22aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "KVUri = \"https://dipanjans-kv.vault.azure.net\"\n",
    "credential = DefaultAzureCredential()\n",
    "client = SecretClient(vault_url=KVUri, credential=credential)\n",
    "\n",
    "\n",
    "oai_endpoint_embed= client.get_secret(\"azure-openai-endpoint-embed\")\n",
    "oai_key_embed=      client.get_secret(\"azure-openai-key-embed\")\n",
    "\n",
    "\n",
    "embeds = AzureOpenAIEmbeddings(azure_deployment=\"dipanjan_ada_embed_150k\",\n",
    "                        model = 'text-embedding-ada-002',\n",
    "                        azure_endpoint= oai_endpoint_embed.value,\n",
    "                        api_key = oai_key_embed.value)\n",
    "\n",
    "####### Testing llm and embed model ######\n",
    "# out = (embeds.embed_query(\"who is this?\"), llm.invoke(\"who is this?\"))\n",
    "# print(out[0])\n",
    "# print(\"****\")\n",
    "# print(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3ced43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# course recommendation RAG assignment\n",
    "def get_df_from_git(github_url):\n",
    "    df = pd.read_csv(github_url)\n",
    "    df['desc_word_len'] = df['description'].apply(lambda x: len(x.split()))\n",
    "    return df , df.shape\n",
    "\n",
    "# github_url = \"https://raw.githubusercontent.com/Bluedata-Consulting/GAAPB01-training-code-base/refs/heads/main/Assignments/assignment2dataset.csv\"\n",
    "# # get_df_from_git(github_url)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f271ac",
   "metadata": {},
   "source": [
    "# Breaking the dataframe into multiple dfs for avoiding token / rate limit errors while generating embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfed0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_and_embed(df, embed_batch_max_word_count):\n",
    "    lst= df['desc_word_len'].tolist()\n",
    "    ind_lst= []\n",
    "    # sum_lst= []\n",
    "    start, end, sum1 = 0,1,lst[0]\n",
    "    while end < len(lst):\n",
    "        if sum1 < embed_batch_max_word_count:\n",
    "            sum1= sum1 + lst[end]\n",
    "            end += 1\n",
    "        else:\n",
    "            # sum_lst.append(sum1 - lst[end-1])\n",
    "            sum1 = 0\n",
    "            ind_lst.append((start, end-1))\n",
    "            start = end-1\n",
    "    else:\n",
    "        ind_lst.append((start, len(lst)))\n",
    "\n",
    "    dfs = [df.iloc[i:j] for i,j in ind_lst] ### Multiple dfs with n(words) < 250\n",
    "    embeds_df = pd.DataFrame()\n",
    "\n",
    "    for i in dfs:\n",
    "        new_df_embed = i.copy()\n",
    "        new_df_embed['desc_embed'] = new_df_embed['description'].apply(embeds.embed_query)\n",
    "        embeds_df= pd.concat([embeds_df, new_df_embed])\n",
    "        time.sleep(2)\n",
    "\n",
    "    embeds_df\n",
    "    \n",
    "    return embeds_df \n",
    "\n",
    "github_url = \"https://raw.githubusercontent.com/Bluedata-Consulting/GAAPB01-training-code-base/refs/heads/main/Assignments/assignment2dataset.csv\"\n",
    "df = get_df_from_git(github_url)[0]\n",
    "df_embeds= divide_and_embed(df, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea7f83",
   "metadata": {},
   "source": [
    "# Push to vectorDB (Using local vecDBs for now, though there are other scalable options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "403f04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db = Chroma(collection_name= 'course_description_vi',\n",
    "                   embedding_function= None, persist_directory= 'chroma_store_as2')\n",
    "chroma_db._collection.add(embeddings= df_embeds['desc_embed'].tolist(),\n",
    "                          ids= list(map(str,df_embeds.index)),\n",
    "                          documents= df_embeds['description'].tolist(),\n",
    "                          metadatas= df_embeds.drop(columns=['description','desc_embed']).to_dict(orient= 'records')\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cbe1d",
   "metadata": {},
   "source": [
    "# Check if upsert success "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad674192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id ----  0\n",
      "metadata ### {'title': 'Foundations of Machine Learning', 'desc_word_len': 50, 'course_id': 'C001'}\n",
      "desc *** Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.\n",
      "id ----  1\n",
      "metadata ### {'course_id': 'C002', 'desc_word_len': 51, 'title': 'Deep Learning with TensorFlow and Keras'}\n",
      "desc *** Explore neural network architectures using TensorFlow and Keras frameworks. This course covers feedforward networks, convolutional neural networks, recurrent neural networks, and transfer learning. Learn to build, train, evaluate, and optimize deep learning models for image classification, sequence modeling, and text processing. Includes hands-on labs and real-world project implementations with interactive exercises.\n",
      "id ----  2\n",
      "metadata ### {'title': 'Natural Language Processing Fundamentals', 'course_id': 'C003', 'desc_word_len': 51}\n",
      "desc *** Dive into NLP techniques for processing and understanding human language. You will learn tokenization, stemming, lemmatization, part-of-speech tagging, named entity recognition, and sentiment analysis. The course includes transformer architectures, attention mechanisms, and fine-tuning pre-trained language models. Hands-on Python labs use Hugging Face and spaCy for end-to-end natural language pipelines and projects.\n",
      "id ----  3\n",
      "metadata ### {'title': 'Computer Vision and Image Processing', 'course_id': 'C004', 'desc_word_len': 54}\n",
      "desc *** Learn the principles of computer vision and image processing. Topics include filtering, edge detection, feature extraction, image segmentation, object detection, and image classification using CNNs. Hands-on labs in Python leverage OpenCV, scikit-image, and TensorFlow. By project’s end, you will build a pipeline to analyze and classify images, detect objects, and perform real-time video processing.\n",
      "id ----  4\n",
      "metadata ### {'title': 'Reinforcement Learning Basics', 'course_id': 'C005', 'desc_word_len': 51}\n",
      "desc *** Get introduced to reinforcement learning paradigms, including Markov decision processes, Q-learning, policy gradients, and actor-critic methods. Learn to formulate environments, design reward functions, and implement agents using OpenAI Gym and TensorFlow. Through guided labs you’ll train agents for classic control tasks and grid-world scenarios, exploring exploration-exploitation trade-offs and model-free learning techniques.\n",
      "id ----  5\n",
      "metadata ### {'desc_word_len': 57, 'course_id': 'C006', 'title': 'Data Engineering on AWS'}\n",
      "desc *** Build scalable data pipelines using AWS services. This course covers S3 data lakes, AWS Glue ETL jobs, AWS Lambda for serverless transformations, Amazon Redshift for warehousing, and AWS Kinesis for streaming ingestion. You’ll design end-to-end pipelines, automate workflows with AWS Step Functions, and monitor performance using CloudWatch, enabling robust, cost-effective data engineering solutions on the AWS cloud.\n",
      "id ----  6\n",
      "metadata ### {'desc_word_len': 54, 'title': 'Cloud Computing with Azure', 'course_id': 'C007'}\n",
      "desc *** Master Microsoft Azure’s core services: virtual machines, Azure Functions, Azure SQL Database, Cosmos DB, and Azure Kubernetes Service. Learn to deploy scalable web applications, configure networking and security, and implement infrastructure-as-code with ARM templates. Hands-on labs guide you through resource provisioning, cost management, and best practices for high availability and disaster recovery in Azure.\n",
      "id ----  7\n",
      "metadata ### {'title': 'DevOps Practices and CI/CD', 'desc_word_len': 53, 'course_id': 'C008'}\n",
      "desc *** Adopt DevOps methodologies to accelerate software delivery. Explore version control with Git, continuous integration with Jenkins or GitHub Actions, infrastructure-as-code with Terraform, and automated testing frameworks. You’ll implement CI/CD pipelines, container registry integration, and blue-green deployments. Through practical labs, learn monitoring with Prometheus and Grafana, fostering a culture of collaboration and rapid iteration.\n",
      "id ----  8\n",
      "metadata ### {'title': 'Containerization with Docker and Kubernetes', 'course_id': 'C009', 'desc_word_len': 51}\n",
      "desc *** Learn container fundamentals with Docker: images, containers, and Compose. Then advance to Kubernetes for orchestration: pods, deployments, services, and ingress. This course covers cluster provisioning, autoscaling, rolling updates, and Helm chart packaging. Hands-on labs deploy microservices architectures on a local or cloud-based Kubernetes cluster, ensuring reliability, scalability, and streamlined DevOps workflows.\n",
      "id ----  9\n",
      "metadata ### {'title': 'APIs and Microservices Architecture', 'course_id': 'C010', 'desc_word_len': 50}\n",
      "desc *** Design and implement RESTful and GraphQL APIs using Node.js, Express, or Python FastAPI. Learn microservices patterns: service discovery, circuit breakers, and API gateways. Topics include containerized deployment, versioning strategies, and security best practices (OAuth2, JWT). Labs guide you through building, testing, and deploying interconnected services, enabling scalable, maintainable distributed systems.\n",
      "id ----  10\n",
      "metadata ### {'title': 'Big Data Analytics with Spark', 'desc_word_len': 54, 'course_id': 'C011'}\n",
      "desc *** Process and analyze large datasets using Apache Spark and PySpark. The course covers RDDs, DataFrames, Spark SQL, and MLlib for machine learning at scale. You’ll learn cluster deployment on YARN or Kubernetes, performance tuning, and structured streaming for real-time analytics. Hands-on projects include building ETL pipelines and interactive dashboards, unlocking insights from big data.\n",
      "id ----  11\n",
      "metadata ### {'course_id': 'C012', 'title': 'SQL for Data Analysis', 'desc_word_len': 54}\n",
      "desc *** Master SQL querying for data analysis and reporting. Topics include SELECT statements, JOINs, subqueries, window functions, CTEs, and aggregate functions. Practice on PostgreSQL or MySQL to manipulate data, generate summary statistics, and create analytical views. Labs cover query optimization, indexing strategies, and writing complex reports, empowering you to derive actionable insights from relational data.\n",
      "id ----  12\n",
      "metadata ### {'desc_word_len': 51, 'course_id': 'C013', 'title': 'NoSQL Databases and MongoDB'}\n",
      "desc *** Explore NoSQL paradigms: key-value, document, column-family, and graph databases. Deep dive into MongoDB: CRUD operations, indexing, aggregation pipeline, replication, and sharding. You’ll design flexible schemas for modern applications, implement transactions, and optimize performance. Through hands-on exercises, build a highly available, horizontally scalable document store and apply best practices for data modeling.\n",
      "id ----  13\n",
      "metadata ### {'course_id': 'C014', 'title': 'Data Visualization with Tableau', 'desc_word_len': 52}\n",
      "desc *** Transform raw data into compelling visual stories using Tableau. Learn to connect to diverse data sources, create interactive dashboards, and apply best practices in chart selection. Topics include calculated fields, parameters, LOD expressions, and storytelling features. Through real-world case studies, you’ll design user-driven analytics that reveal trends and drive data-informed decision making.\n",
      "id ----  14\n",
      "metadata ### {'course_id': 'C015', 'title': 'Business Intelligence with Power BI', 'desc_word_len': 51}\n",
      "desc *** Leverage Microsoft Power BI to build dynamic business intelligence solutions. Cover data ingestion, Power Query transformations, DAX calculations, and interactive report design. You’ll publish dashboards to the Power BI service, set up data refresh schedules, and manage security. Practical labs simulate enterprise scenarios, enabling you to deliver actionable insights at scale.\n",
      "id ----  15\n",
      "metadata ### {'title': 'Python Programming for Data Science', 'course_id': 'C016', 'desc_word_len': 51}\n",
      "desc *** Learn Python fundamentals for data science: variables, control flow, functions, and object-oriented programming. Advance to data handling with pandas, numerical computing with NumPy, and basic plotting with matplotlib. You’ll build reproducible data workflows, clean and transform datasets, and perform exploratory analysis, laying the groundwork for machine learning and statistical modeling projects.\n",
      "id ----  16\n",
      "metadata ### {'course_id': 'C017', 'desc_word_len': 50, 'title': 'R Programming and Statistical Analysis'}\n",
      "desc *** Get introduced to R for statistical computing and graphics. Topics include data structures, control flow, and functional programming. Use tidyverse libraries—dplyr, ggplot2, tidyr—for data manipulation and visualization. Explore hypothesis testing, regression analysis, and ANOVA. Through labs, apply statistical methods to real-world datasets and communicate results with reproducible R Markdown reports.\n",
      "id ----  17\n",
      "metadata ### {'title': 'Product Management Essentials', 'course_id': 'C018', 'desc_word_len': 53}\n",
      "desc *** Understand the product lifecycle from ideation to launch. Topics cover market research, roadmap planning, agile development, and stakeholder management. Learn to write user stories, prioritize features, and measure success with KPIs. Hands-on case studies guide you through creating product requirement documents, conducting customer interviews, and iterating based on feedback to drive product-market fit.\n",
      "id ----  18\n",
      "metadata ### {'course_id': 'C019', 'desc_word_len': 51, 'title': 'Agile and Scrum Mastery'}\n",
      "desc *** Adopt Agile frameworks to enhance team productivity. This course covers Scrum roles, ceremonies, artifacts, and scaling with SAFe. Learn backlog grooming, sprint planning, retrospectives, and agile metrics. Interactive simulations and group exercises help you practice facilitation, conflict resolution, and continuous improvement, equipping you to lead high-performing agile teams in dynamic environments.\n",
      "id ----  19\n",
      "metadata ### {'course_id': 'C020', 'title': 'User Experience (UX) Design Principles', 'desc_word_len': 51}\n",
      "desc *** Learn UX design fundamentals: user research, personas, journey mapping, wireframing, and prototyping. Utilize tools like Figma to create interactive mockups. Topics include usability testing, accessibility standards, and design systems. Through project-based labs, you’ll design and test intuitive interfaces, apply heuristics, and iterate based on user feedback to craft delightful digital experiences.\n",
      "id ----  20\n",
      "metadata ### {'course_id': 'C021', 'desc_word_len': 53, 'title': 'Cybersecurity Fundamentals'}\n",
      "desc *** Get introduced to cybersecurity principles: threat modeling, encryption, network security, and incident response. Learn about common vulnerabilities (OWASP Top 10), secure coding practices, and vulnerability assessment tools. Hands-on labs include configuring firewalls, running penetration tests with Kali Linux, and implementing multi-factor authentication, preparing you to protect systems and data against modern cyber threats.\n",
      "id ----  21\n",
      "metadata ### {'title': 'Internet of Things (IoT) Development', 'course_id': 'C022', 'desc_word_len': 52}\n",
      "desc *** Explore IoT architecture, sensors, and edge computing. Use Raspberry Pi or Arduino to collect data, process it with MQTT, and store it in cloud services. Topics include device provisioning, security, and real-time analytics. Hands-on projects build smart home prototypes and industrial monitoring solutions, teaching you end-to-end IoT development and deployment best practices.\n",
      "id ----  22\n",
      "metadata ### {'desc_word_len': 45, 'title': 'Blockchain Technology and Smart Contracts', 'course_id': 'C023'}\n",
      "desc *** Understand blockchain fundamentals: cryptographic hashing, consensus algorithms, and distributed ledgers. Learn to develop smart contracts using Solidity on Ethereum. Topics include token standards (ERC-20, ERC-721), decentralized application patterns, and security best practices. Hands-on labs deploy contracts, interact via Web3.js, and build a simple decentralized marketplace.\n",
      "id ----  23\n",
      "metadata ### {'course_id': 'C024', 'desc_word_len': 52, 'title': 'Augmented and Virtual Reality Development'}\n",
      "desc *** Dive into AR/VR concepts, device ecosystems, and development frameworks like Unity and Unreal Engine. Learn to build immersive experiences, handle 3D assets, and implement input interactions. Topics cover spatial computing, UI/UX for XR, and performance optimization. Through labs, you’ll create both AR and VR prototypes for education, training, or entertainment use cases.\n",
      "id ----  24\n",
      "metadata ### {'title': 'MLOps: Productionizing Machine Learning', 'desc_word_len': 51, 'course_id': 'C025'}\n",
      "desc *** Master the practices needed to deploy and maintain ML models at scale. Topics include model versioning with MLflow, containerization, CI/CD for ML, monitoring with Prometheus, and data drift detection. You’ll build end-to-end pipelines that automate training, testing, deployment, and governance, ensuring robust, reproducible, and compliant machine learning systems in production environments.\n"
     ]
    }
   ],
   "source": [
    "chroma_db = Chroma(collection_name= 'course_description_vi',\n",
    "                   embedding_function= None, persist_directory= 'chroma_store_as2')\n",
    "all_docs = chroma_db._collection.get()\n",
    "for i in range(len(all_docs['ids'])):\n",
    "    print('id ---- ', all_docs['ids'][i])\n",
    "    print('metadata ###', all_docs['metadatas'][i])\n",
    "    print('desc ***', all_docs['documents'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f08267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98e621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
